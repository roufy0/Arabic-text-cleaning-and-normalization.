{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "import pandas as pd\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "9-5VO_HVSFb_"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Text Cleaning and normalization"
      ],
      "metadata": {
        "id": "r1taXw8bXJAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Regular expressions for cleaning\n",
        "DIACRITICS_RE = re.compile(r\"[ؐ-ًؚ-ٟۖ-ۭ]\")\n",
        "TATWEEL = \"ـ\"\n",
        "ALLOWED_CHARS_RE = re.compile(r\"[^ء-غف-ي0-9A-Za-z@ ]\")\n",
        "ARAB2WEST_DIGITS = str.maketrans(\"٠١٢٣٤٥٦٧٨٩\", \"0123456789\")"
      ],
      "metadata": {
        "id": "NnTNMkE7XZD9"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RAW_SAMPLES = [\n",
        "    \"\"\"\n",
        "_َ ُِٕ(~عذٌّٕاٍرًَ ٕٕطٌَّبًَية~)« Sَkَََ«lifَ  مٕ.عٕٕتٕمدَ)»٠꧂\n",
        "0549837023\n",
        "\"\"\",\n",
        "    \"\"\"ٓٓســ.ـكـِلـ.ــيـ.ـف\n",
        "ٓٓ مــعـ.ـتــمد صــحـ.ـتــي ✅\n",
        "ٓتاريـخ قـديـم تاريـخ جديد ✅\n",
        "ٓاشـ ـعـار مــ ـرافق ✅\n",
        "ٓتـ.ـقـ.ـريـــر طـبـي ✅\n",
        "ٓسعر مميزز0560516730\"\"\",\n",
        "    \"\"\"♻️*سـ░ـكــ ░ـلَـ يـ░ــ ـفـ░ـ*♻️\n",
        "✨ آجـ ـ░ـآزٍآتـ ـ░ـ ⭐مـ░ــ ـرٍضــ ░ـيـ░ـةّ\n",
        "✨ رٍسـ░ـ⭐ـ ـمـ░ـيـ░ﻲ معتمد\n",
        "✅ࡎ✔️ߺܒߺࡅ𐫥ߺߺى  لدفع بعد الانجاز 0562451912\"\"\",\n",
        "    \"\"\"س\n",
        "         ك\n",
        "         ل\n",
        "      ي\n",
        "ف\n",
        "        ا\n",
        "           ع\n",
        "        ذ\n",
        "     ا\n",
        " ر\n",
        "ط\n",
        "     ب\n",
        "     ي\n",
        "ة\n",
        "خ\n",
        "ا\n",
        " ص\"\"\",\n",
        "    \"\"\"🔴 للفائدة 🔴\n",
        "أي طالب يبحث عن شرح لأي مادة طبية\n",
        "حرفيًا أي مادة طبية ويبي شرح للمادة سواء يبي للمادة بالكامل أو بعض المحاضرات\n",
        "أنصحكم بأكاديمية دوكاديمي\n",
        "@DOCADEMYKSA\n",
        "@DOCADEMY\"\"\",\n",
        "]"
      ],
      "metadata": {
        "id": "e86VukR_Xc5F"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Goal 1: Cleaning and normalizing Arabic text."
      ],
      "metadata": {
        "id": "E_zVqPMVXz1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text: str) -> str:\n",
        "    text = unicodedata.normalize(\"NFC\", text)  # Normalize Unicode\n",
        "    text = DIACRITICS_RE.sub(\"\", text)  # Remove diacritics\n",
        "    text = text.replace(TATWEEL, \"\")  # Remove Tatweel\n",
        "    text = text.translate(ARAB2WEST_DIGITS)  # Convert Arabic digits to Western\n",
        "    text = ALLOWED_CHARS_RE.sub(\" \", text)  # Remove unwanted characters\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()  # Remove extra spaces\n",
        "    return text"
      ],
      "metadata": {
        "id": "rk5NZonNXi6L"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Goal 2: Reconstructs fragmented Arabic words."
      ],
      "metadata": {
        "id": "CvRQO3W3X8bn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reconstruct_words(text: str) -> str:\n",
        "    tokens = text.split()\n",
        "    reconstructed, buffer = [], []\n",
        "\n",
        "    for token in tokens:\n",
        "        if re.fullmatch(r\"[ء-ي]\", token):  # If single Arabic letter\n",
        "            buffer.append(token)\n",
        "        else:\n",
        "            if buffer:\n",
        "                reconstructed.append(\"\".join(buffer))\n",
        "                buffer.clear()\n",
        "            reconstructed.append(token)\n",
        "\n",
        "    if buffer:\n",
        "        reconstructed.append(\"\".join(buffer))\n",
        "\n",
        "    return \" \".join(reconstructed)"
      ],
      "metadata": {
        "id": "0ahwstZOXmT0"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Goal 3: Processing and generating the output file"
      ],
      "metadata": {
        "id": "9IFyEnQTYKtO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_messages(messages):\n",
        "    cleaned_messages = [reconstruct_words(clean_text(msg)) for msg in messages]\n",
        "    return cleaned_messages\n",
        "\n",
        "def save_output(messages, filename=\"cleaned_messages.txt\"):\n",
        "    Path(filename).write_text(\"\\n\".join(messages), encoding=\"utf-8\")\n",
        "    print(f\"✅ Saved → {Path(filename).resolve()}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    cleaned = process_messages(RAW_SAMPLES)\n",
        "    save_output(cleaned)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSscbVXRXp2A",
        "outputId": "98e1408e-deb2-40fc-f34c-9fc0eb2056c7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved → /content/cleaned_messages.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering File"
      ],
      "metadata": {
        "id": "NbPeBMtCYY5j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Goal 1: Define the Regular expressions for feature extraction"
      ],
      "metadata": {
        "id": "cMJKHJtSZnzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PHONE_NUMBER_RE = re.compile(r\"\\b\\d{9,}\\b\")\n",
        "TELEGRAM_USERNAME_RE = re.compile(r\"@\\w+\")\n",
        "\n",
        "AD_KEYWORDS = {\n",
        "    \"سكليف\", \"اعذار\", \"إجازات\", \"مرضية\", \"تقرير\", \"طبية\", \"معتمد\", \"صحتى\",\n",
        "    \"تاريخ\", \"قديم\", \"جديد\", \"اشعار\", \"مرافق\", \"سعر\", \"مميز\", \"لدفع\", \"بعد\", \"الانجاز\", \"فوري\", \"خاص\"\n",
        "}"
      ],
      "metadata": {
        "id": "jQgvs6pKY-MI"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Goal 2: Feature Extraction Functions"
      ],
      "metadata": {
        "id": "fshD6oZ7ZL1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_phone_numbers(text: str) -> list:\n",
        "    return PHONE_NUMBER_RE.findall(text)\n",
        "\n",
        "def extract_telegram_accounts(text: str) -> list:\n",
        "    return TELEGRAM_USERNAME_RE.findall(text)\n",
        "\n",
        "def count_ad_keywords(text: str) -> int:\n",
        "    return sum(text.count(keyword) for keyword in AD_KEYWORDS)\n",
        "\n",
        "def is_ad(text: str) -> bool:\n",
        "    return bool(extract_phone_numbers(text)) or bool(extract_telegram_accounts(text)) or count_ad_keywords(text) > 0"
      ],
      "metadata": {
        "id": "akA8eQlmWpPM"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Goal 3: process the list of cleaned messages and build the dataframe"
      ],
      "metadata": {
        "id": "3lKWsXbCZcbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_features(messages):\n",
        "    data = []\n",
        "\n",
        "    for msg in messages:\n",
        "        phone_numbers = extract_phone_numbers(msg)\n",
        "        telegram_accounts = extract_telegram_accounts(msg)\n",
        "        num_keywords = count_ad_keywords(msg)\n",
        "        ad_label = \"ad\" if is_ad(msg) else \"not_ad\"\n",
        "\n",
        "        data.append({\n",
        "            \"cleaned_message\": msg,\n",
        "            \"phone_numbers\": \", \".join(phone_numbers),\n",
        "            \"telegram_accounts\": \", \".join(telegram_accounts),\n",
        "            \"num_ad_keywords\": num_keywords,\n",
        "            \"is_ad\": ad_label\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "E_1aN8RoZYtO"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Goal 4: saves the dataframe into a csv file"
      ],
      "metadata": {
        "id": "pIGT-UBPaFHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_dataframe(df, filename=\"processed_features.csv\"):\n",
        "    df.to_csv(filename, index=False, encoding=\"utf-8\")\n",
        "    print(f\"✅ Saved → {Path(filename).resolve()}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    cleaned_messages = process_messages(RAW_SAMPLES)  # Get cleaned messages\n",
        "    df = process_features(cleaned_messages)\n",
        "    save_dataframe(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HW0c3pM0aCn9",
        "outputId": "df2a65b4-9e82-49a6-ca38-b8593e23132d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved → /content/processed_features.csv\n"
          ]
        }
      ]
    }
  ]
}